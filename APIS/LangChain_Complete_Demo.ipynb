{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lanchain Docs: https://python.langchain.com/docs/get_started/introduction"
      ],
      "metadata": {
        "id": "gCS0Jlgukgxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intsall"
      ],
      "metadata": {
        "id": "mJ2XBKTTklFp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tctkt8vpjQBh",
        "outputId": "03ebaf5d-0822-4c9b-d5f5-2aa79a6c0098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.23 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment Variables"
      ],
      "metadata": {
        "id": "V3XvMTLjkwZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HUGGINGFACEHUB_API_TOKEN = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "RZvq4C4SkpqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "pF5m40i8lZS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Open AI\n",
        "\n",
        "Example 1"
      ],
      "metadata": {
        "id": "spgMerxomNql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ7TkEs6mJ9-",
        "outputId": "f966b88a-13db-4415-93c1-96e332ed64e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "temperature value--> how creative we want our model to be\n",
        "\n",
        "0 ---> temperature it means model is  very safe it is not taking any bets.\n",
        "\n",
        "1 --> it will take risk it might generate wrong output but it is very creative"
      ],
      "metadata": {
        "id": "J3FHNuJgnIcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature= 0.9)"
      ],
      "metadata": {
        "id": "b1qhxcDLmTye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\""
      ],
      "metadata": {
        "id": "w2B_5FDQmj6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.predict(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1jaF4sboTJ1",
        "outputId": "ceb62016-9992-45ff-cfbf-32a463fe846c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Socksplosion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIdb5_swoa-2",
        "outputId": "fb1eb54e-da18-4d51-a616-f1983e78c7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Threads\" or \"Vibrant Socks Co.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai1YyNZXpCbI",
        "outputId": "1cce402b-15e0-4981-fbfd-14038fe6e141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Vibrant Socks Co.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example 2"
      ],
      "metadata": {
        "id": "uQPpqsCTp5Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature= 0.9)"
      ],
      "metadata": {
        "id": "sVbNFdLEpCYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I want to open a restaurant for Indian Food. suggest a fency name for this.\""
      ],
      "metadata": {
        "id": "VEIND0yLp_ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNm8fv8uqLkO",
        "outputId": "57bba053-6a16-4d54-89ab-7ccce0f0d611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\"Dragon's Palace\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face\n",
        "\n",
        "Example 1"
      ],
      "metadata": {
        "id": "lJlKCBZSq4-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdjbXJxVqNl_",
        "outputId": "503da700-2f57-41ed-c439-7fcf80c1ca45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "lB_qBqrSrBhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-large\", model_kwargs={\"temperature\": 0.5})"
      ],
      "metadata": {
        "id": "3Wl8E1vXrKa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"translate English to German: How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gjlKnL48sDHn",
        "outputId": "41649a84-9c95-434c-a295-7d647faac6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wie sind Sie?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0})\n",
        "name = llm.predict(\"I want to open a restaurant for Chinese food. Suggest a fency name for this.\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS7r5CgUsPL1",
        "outputId": "e0c46237-43f4-437f-bfad-e6fac0271f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinese restaurant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm= HuggingFaceHub(repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1',model_kwargs={'temperature':1})\n",
        "\n",
        "llm(\"Translate english to hindi : How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "LLwDD5_itJq1",
        "outputId": "ff377c90-ba53-49ee-881f-f4abf86a2dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Translate english to hindi : How are you?\\n\\nTranslation of How are you in Hindi: आप कैसे हैं?\\n\\nAlso Read: How to say I love you in Hindi\\n\\n## How to say How are you in Hindi\\n\\nTo say How are you in Hindi, you can say आप कैसे हैं?\\n\\nThis is the most common way to ask someone how they are doing in Hindi.\\n\\nHere'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Templates"
      ],
      "metadata": {
        "id": "DPjJDpu6t0VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9)\n",
        "\n",
        "llm(\"I want to open a restaurant for Bengali Food. suggest a fency name for this.\")\n",
        "llm(\"I want to open a restaurant for Indain Food. suggest a fency name for this.\")\n",
        "llm(\"I want to open a restaurant for German Food. suggest a fency name for this.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CRL7zcRazpfi",
        "outputId": "2f53a76a-3a79-4302-88be-4592f27eee6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\"Shondesh Bites\" '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "p = prompt_template_name.format(cuisine=\"Indian\")\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1EjlizJtiWW",
        "outputId": "b4def9ac-7451-4d3a-c16a-f02d88eaf2a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to open a restaurant for Indian food. Suggest a fency name for this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"colorful socks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w6YmV9WPulN_",
        "outputId": "6fb0bcf7-b555-432d-cfc1-ea00a43aa6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chains"
      ],
      "metadata": {
        "id": "zQ3HYAASv0Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)"
      ],
      "metadata": {
        "id": "1KjfUviivnCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
        "prompt.format(product=\"colorful socks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4vAJd5UTwFB2",
        "outputId": "4cf41a77-d00c-4df9-ef43-02af4c86272f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is a good name for a company that makes colorful socks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "response= chain.run(\"colorful socks\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHi-lbngwH9n",
        "outputId": "0fce95a7-9595-4b34-ca23-517abdda3a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Rainbow Threads\" or \"Vibrant Sock Co.\" would be good options for a company that makes colorful socks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm= HuggingFaceHub(repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1',model_kwargs={'temperature':1})\n"
      ],
      "metadata": {
        "id": "V0aEDwNHyRx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt, verbose= True)\n",
        "response= chain.run(\"colorful socks\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF5h7oclwX7H",
        "outputId": "739c25bc-872f-46d6-acd2-abad6bc06d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mWhat is a good name for a company that makes colorful socks\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "What is a good name for a company that makes colorful socks?\n",
            "\n",
            "A good name for a company that makes colorful socks could be \"Vibrant Soles\" or \"Rainbow Feet\". These names play off the idea of bright, colorful socks and create a fun, playful image for the brand. Other options could include \"ChromaSocks\", \"Spectrum Socks\", or \"Color Crew Socks\". Ultimately, the name should reflect the unique and colorful nature of the socks and appeal to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Sequential Chain"
      ],
      "metadata": {
        "id": "Y_ebdWiF4uKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.6)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
        ")\n",
        "\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AHrG66u6yEzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])"
      ],
      "metadata": {
        "id": "2MdZi2MO5dPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content = chain.run(\"indian\")\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RCzrs4d55XR",
        "outputId": "05a63c56-434d-442a-ba2f-391f0b8728de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Saffron Chicken Tikka Masala\n",
            "2. Saffron Rice Pilaf\n",
            "3. Saffron Shrimp Curry\n",
            "4. Saffron Vegetable Biryani\n",
            "5. Saffron Lamb Kebabs\n",
            "6. Saffron Naan Bread\n",
            "7. Saffron Cauliflower Soup\n",
            "8. Saffron Pistachio Ice Cream\n",
            "9. Saffron Roasted Eggplant Dip\n",
            "10. Saffron Cardamom Chai Latte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Chain"
      ],
      "metadata": {
        "id": "2-20WpBB7LIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
        "\n",
        "\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
      ],
      "metadata": {
        "id": "by7C5mJB5_qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain],\n",
        "    input_variables = ['cuisine'],\n",
        "    output_variables = ['restaurant_name', \"menu_items\"]\n",
        ")"
      ],
      "metadata": {
        "id": "OERFgkHb7OrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain({\"cuisine\": \"indian\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQkGULq17gUI",
        "outputId": "e33cfd12-79f3-400e-be2b-e862b037ce2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': 'indian', 'restaurant_name': '\\n\\n\"Saffron Spice Bistro\"', 'menu_items': '\\n\\n1. Saffron Chicken Tikka Masala\\n2. Lamb Biryani\\n3. Vegetable Samosas\\n4. Tandoori Shrimp Skewers\\n5. Palak Paneer (spinach and cheese curry)\\n6. Naan Bread with Garlic and Herb Butter\\n7. Chicken Korma\\n8. Spicy Chickpea Curry\\n9. Mango Lassi (yogurt-based drink)\\n10. Gulab Jamun (traditional Indian dessert)\\n11. Tandoori Mixed Grill (assorted grilled meats)\\n12. Aloo Gobi (potato and cauliflower curry)\\n13. Malai Kofta (vegetable and cheese dumplings in creamy sauce)\\n14. Chicken Vindaloo\\n15. Masala Chai (spiced tea).'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents and Tools"
      ],
      "metadata": {
        "id": "YyYGuUCs8UhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD-a4Ds07l-w",
        "outputId": "860e59a2-2111-4c16-f080-9023e559e168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=ff10271a058e2279ca8d0a0c978ff4af852a4c0c39c7cf4dddb90a2d7001d944\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://serpapi.com/"
      ],
      "metadata": {
        "id": "j0Hx4gYy-2te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['SERPAPI_API_KEY'] = '549f81289e4db0bd6e8907247de5093f59d261b62dd0d65890aa5dab3fe89835'"
      ],
      "metadata": {
        "id": "8bcXWL0s-wSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "#Google Search API\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"What was the GDP of US in 2023?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ut3lJT8V_Cwb",
        "outputId": "ef320650-5282-4fcc-ab64-7fa03ad0b8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should search for the answer using a search engine.\n",
            "Action: Search\n",
            "Action Input: \"GDP of US in 2023\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m$27.36 trillion\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to convert the GDP from dollars to another currency if needed.\n",
            "Action: Calculator\n",
            "Action Input: $27.36 trillion\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 27360000000000\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should double check the accuracy of the information I found.\n",
            "Action: Search\n",
            "Action Input: \"Is the GDP of US in 2023 really $27.36 trillion?\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mCurrent-dollar GDP increased 6.3 percent, or $1.61 trillion, in 2023 to a level of $27.36 trillion, compared with an increase of 9.1 percent, or $2.15 trillion, in 2022 (tables 1 and 3).\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The GDP of US in 2023 was $27.36 trillion.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The GDP of US in 2023 was $27.36 trillion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSOPujHgArBn",
        "outputId": "8369953b-35b4-4f41-a291-c3921fed39c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=93dd4641e8023617d768e6c193be18736b04729f10ea6876d199f0afdbb6bb9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install this package: pip install wikipedia\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the 0.43 power?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "yxpWi4KQ_aOB",
        "outputId": "726af303-cbbf-40a5-fa86-dee07a9e77d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find the release year of the film and then use the Calculator to raise it to the 0.43 power.\n",
            "Action: wikipedia\n",
            "Action Input: Departed film\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: The Departed\n",
            "Summary: The Departed is a 2006 American crime thriller film directed by Martin Scorsese and written by William Monahan. It is both a remake of the 2002 Hong Kong film Infernal Affairs and also loosely based on the real-life Boston Winter Hill Gang; the character Colin Sullivan is based on the corrupt FBI agent John Connolly, while the character Frank Costello is based on Irish-American gangster and crime boss Whitey Bulger. The film stars Leonardo DiCaprio, Matt Damon, Jack Nicholson, and Mark Wahlberg, with Martin Sheen, Ray Winstone, Vera Farmiga, Alec Baldwin, Anthony Anderson and James Badge Dale in supporting roles.\n",
            "The film takes place in Boston and the surrounding metro area, primarily in the South Boston neighborhood. Irish Mob boss Frank Costello (Nicholson) plants Colin Sullivan (Damon) as a spy within the Massachusetts State Police; simultaneously, the police assign undercover state trooper Billy Costigan (DiCaprio) to infiltrate Costello's mob crew. When both sides realize the situation, Sullivan and Costigan each attempt to discover the other's identity before they are found out.\n",
            "The Departed was a critical and commercial success, receiving acclaim for its direction, performances (particularly of DiCaprio, Nicholson, and Wahlberg), screenplay, and editing.\n",
            "It won several accolades, including four Oscars at the 79th Academy Awards: for Best Picture, Best Director, Best Adapted Screenplay, and Best Film Editing. It remains Scorsese's only personal Oscar win. The film also received six nominations each at the 64th Golden Globe Awards and the 60th British Academy Film Awards, and two nominations at the 13th Screen Actors Guild Awards.\n",
            "\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now that I know the release year, I can use the Calculator to raise it to the 0.43 power.\n",
            "Action: Calculator\n",
            "Action Input: 2006 ^ 0.43\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 26.30281917656938\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 26.30281917656938\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'26.30281917656938'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Memory"
      ],
      "metadata": {
        "id": "fJTBqChHB8m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)"
      ],
      "metadata": {
        "id": "3nd9ptv7AoXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
        ")"
      ],
      "metadata": {
        "id": "bqi_uW8JCKxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8CAyCt7CNb_",
        "outputId": "29acdcb5-d960-4e50-d84c-433d5386aa9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Cantina del Sol\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faLoAxhuCQdX",
        "outputId": "432b146c-8fef-474d-a1ca-45836178940f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Spice Symphony\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brup8upNCY4h",
        "outputId": "3438c4ce-29af-4345-84ba-0f8057bc62ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConversationBufferMemory"
      ],
      "metadata": {
        "id": "mc8CxBCnCe1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yujyr3ZRCapP",
        "outputId": "cc22cba7-bafa-4263-a0e0-84d010d86926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Sabores de México\" (\"Flavors of Mexico\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCN7T8PICjt4",
        "outputId": "195ca6ff-7853-49d9-b2f7-1b5189ff2a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"Maharaja's Palace\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5TxeDCcCloS",
        "outputId": "14c0fd80-a57b-448c-f111-b5a3ab530705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexican\n",
            "AI: \n",
            "\"Sabores de México\" (\"Flavors of Mexico\")\n",
            "Human: Indian\n",
            "AI: \n",
            "\"Maharaja's Palace\"\n",
            "Human: Bengali\n",
            "AI: \n",
            "\n",
            "\"Mangsher Manor\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Bengali\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivv367TICn8I",
        "outputId": "5e2dd4dd-cb77-46dc-993f-2244bd4ec0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Mangsher Manor\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConversationChain"
      ],
      "metadata": {
        "id": "dBe7LiJ7C_fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
        "print(convo.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc_ZxMQYC-90",
        "outputId": "f8a1e0d5-4b14-43ef-bc16-06b3b10d9a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "bAzVynhNDD9D",
        "outputId": "26f2fd70-62d4-432c-cdb4-a8f205ce7ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first cricket World Cup was held in 1975 and was won by the West Indies team. They defeated Australia in the final by 17 runs. It was a historic moment for the West Indies as they became the first team to win the World Cup. Do you want to know more about the World Cup or the teams that participated?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YVX3DVaGDILL",
        "outputId": "d9e1327e-424f-4254-ad77-82a5f9d9231b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 5+5 is equal to 10. Do you want to know more about the mathematical concept of addition or do you have any other questions?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ndt194M6DLXK",
        "outputId": "b5f368bc-376f-4ed1-bd64-74cc388b92c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the West Indies team during the first cricket World Cup was Clive Lloyd. He also won the Player of the Match award in the final for his performance. The other members of the team included players like Viv Richards, Gordon Greenidge, and Michael Holding. Is there anything else you would like to know?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "Vht2t-qlC3k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=2)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.run(\"Who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8x_g9i1tCxNv",
        "outputId": "244937c5-e6c6-48f6-f7f0-06d63cc950ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first cricket world cup was won by the West Indies team in 1975.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5lSr-Qo3DlXJ",
        "outputId": "e8ec1a3a-4e3e-48c6-9f2d-f03131b6a480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 5+5 is equal to 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"Who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K9iUgaRyDoW0",
        "outputId": "d69a973c-83a7-404e-a8b2-fcb8465f8186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the West Indies team during the first cricket world cup was Clive Lloyd.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Loaders"
      ],
      "metadata": {
        "id": "963y_C0rFI92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vBNssKjFX0N",
        "outputId": "73f137f1-2fca-4942-c73e-77742504d0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/286.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/286.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/Report - Importance and the use of correlation in Statistics.pdf\")\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "tQlk2AISDrMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw5eLIRNFbLs",
        "outputId": "8f5f77a8-ee4f-41cb-a78c-01cc2866004d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Importance\\nand\\nthe\\nuse\\nof\\ncorrelation\\nin\\nStatistics\\nIntroduction\\nCorrelation\\nis\\na\\nstatistical\\nmeasure\\nthat\\nexpresses\\nthe\\nextent\\nto\\nwhich\\ntwo\\nvariables\\nare\\nlinearly\\nrelated.\\nIt\\nis\\na\\ncommon\\ntool\\nfor\\ndescribing\\nsimple\\nrelationships\\nwithout\\nmaking\\na\\nstatement\\nabout\\ncause\\nand\\neffect.\\nCorrelation\\ncoefficients\\nrange\\nfrom\\n-1\\nto\\n1,\\nwith\\na\\nvalue\\nof\\n0\\nindicating\\nno\\nlinear\\nrelationship\\nbetween\\nthe\\ntwo\\nvariables,\\na\\nvalue\\nof\\n1\\nindicating\\na\\nperfect\\npositive\\nlinear\\nrelationship,\\nand\\na\\nvalue\\nof\\n-1\\nindicating\\na\\nperfect\\nnegative\\nlinear\\nrelationship.\\nCorrelation\\nis\\nimportant\\nin\\nstatistics\\nbecause\\nit\\ncan\\nbe\\nused\\nto\\n1.\\nIdentify\\nrelationships\\nbetween\\nvariables:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nwhether\\nthere\\nis\\na\\nrelationship\\nbetween\\ntwo\\nvariables,\\nand\\nif\\nso,\\nwhether\\nthe\\nrelationship\\nis\\npositive\\nor\\nnegative.\\nThis\\ninformation\\ncan\\nbe\\nuseful\\nfor\\nunderstanding\\nthe\\nrelationships\\nbetween\\ndifferent\\nfactors\\nin\\na\\ncomplex\\nsystem.\\n2.\\nMake\\npredictions:\\nIf\\nthere\\nis\\na\\nstrong\\ncorrelation\\nbetween\\ntwo\\nvariables,\\nit\\nis\\npossible\\nto\\nuse\\nthe\\nvalue\\nof\\none\\nvariable\\nto\\npredict\\nthe\\nvalue\\nof\\nthe\\nother\\nvariable.\\nThis\\ncan\\nbe\\nuseful\\nfor\\nmaking\\npredictions\\nin\\na\\nvariety\\nof\\nfields,\\nsuch\\nas\\nbusiness,\\nfinance,\\nand\\nmedicine.\\n3.\\nDevelop\\ncausal\\nmodels:\\nCorrelation\\ncan\\nbe\\nused\\nas\\na\\nstarting\\npoint\\nfor\\ndeveloping\\ncausal\\nmodels,\\nwhich\\nare\\nmodels\\nthat\\ndescribe\\nhow\\nchanges\\nin\\none\\nvariable\\ncause\\nchanges\\nin\\nother\\nvariables.\\nCausal\\nmodels\\ncan\\nbe\\nused\\nto\\nmake\\nmore\\naccurate\\npredictions\\nand\\nto\\ndevelop\\ninterventions\\nto\\nchange\\nthe\\nvalues\\nof\\nspecific\\nvariables.', metadata={'source': '/content/Report - Importance and the use of correlation in Statistics.pdf', 'page': 0}),\n",
              " Document(page_content='Correlation\\nis\\nused\\nin\\na\\nwide\\nvariety\\nof\\nfields\\nincluding\\n1.\\nBusiness:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nbusiness\\nvariables,\\nsuch\\nas\\nsales,\\nadvertising\\nspending,\\nand\\ncustomer\\nsatisfaction.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nmake\\nbetter\\nbusiness\\ndecisions,\\nsuch\\nas\\nhow\\nto\\nallocate\\nmarketing\\nresources.\\n2.\\nFinance:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nfinancial\\nassets,\\nsuch\\nas\\nstocks,\\nbonds,\\nand\\ncommodities.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nbuild\\ndiversified\\nportfolios\\nthat\\nreduce\\nrisk.\\n3.\\nMedicine:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\nmedical\\nvariables,\\nsuch\\nas\\nrisk\\nfactors\\nfor\\ndiseases\\nand\\nthe\\neffectiveness\\nof\\ntreatments.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\nimprove\\nthe\\nprevention,\\ndiagnosis,\\nand\\ntreatment\\nof\\ndiseases.\\n4.\\nPsychology:\\nCorrelation\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\ndifferent\\npsychological\\nvariables,\\nsuch\\nas\\npersonality\\ntraits,\\ncognitive\\nabilities,\\nand\\nmental\\ndisorders.\\nThis\\ninformation\\ncan\\nbe\\nused\\nto\\ndevelop\\nbetter\\npsychological\\nassessments\\nand\\ntreatments.\\nHow\\ncorrelation\\nis\\nused\\nin\\nthe\\nreal\\nworld\\n1.\\nA\\nmarketing\\nmanager\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nadvertising\\nspending\\nand\\nsales.\\nThis\\ninformation\\ncould\\nbe\\nused\\nto\\ndecide\\nhow\\nmuch\\nmoney\\nto\\nallocate\\nto\\nadvertising.\\n2.\\nA\\nfinancial\\nanalyst\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nthe\\nreturns\\nof\\ndifferent\\nstocks.\\nThis\\ninformation\\ncould\\nbe', metadata={'source': '/content/Report - Importance and the use of correlation in Statistics.pdf', 'page': 1}),\n",
              " Document(page_content='used\\nto\\nbuild\\na\\nportfolio\\nof\\nstocks\\nthat\\nis\\ndiversified\\nand\\nhas\\na\\nlower\\noverall\\nrisk.\\n3.\\nA\\nmedical\\nresearcher\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nsmoking\\nand\\nlung\\ncancer.\\nThis\\ninformation\\ncould\\nbe\\nused\\nto\\ndevelop\\npublic\\nhealth\\ncampaigns\\nto\\ndiscourage\\nsmoking.\\n4.\\nA\\npsychologist\\nmight\\nuse\\ncorrelation\\nto\\nidentify\\nthe\\nrelationship\\nbetween\\nanxiety\\nand\\ndepression.\\nThis\\ninformation\\ncould\\nbe\\nused\\nto\\ndevelop\\nmore\\neffective\\ntreatments\\nfor\\nanxiety\\nand\\ndepression.\\nConclusion\\nIt\\nis\\nimportant\\nto\\nnote\\nthat\\ncorrelation\\ndoes\\nnot\\nequal\\ncausation.\\nJust\\nbecause\\ntwo\\nvariables\\nare\\ncorrelated\\ndoes\\nnot\\nmean\\nthat\\none\\nvariable\\ncauses\\nthe\\nother .\\nFor\\nexample,\\nthere\\nis\\na\\nstrong\\ncorrelation\\nbetween\\nice\\ncream\\nsales\\nand\\nshark\\nattacks.\\nHowever ,\\nthis\\ndoes\\nnot\\nmean\\nthat\\neating\\nice\\ncream\\ncauses\\nshark\\nattacks.\\nInstead,\\nthere\\nis\\nlikely\\na\\nthird\\nvariable,\\nsuch\\nas\\nhot\\nweather ,\\nthat\\ncauses\\nboth\\nice\\ncream\\nsales\\nand\\nshark\\nattacks\\nto\\nincrease.\\nOverall,\\ncorrelation\\nis\\na\\npowerful\\nstatistical\\ntool\\nthat\\ncan\\nbe\\nused\\nto\\nidentify\\nrelationships\\nbetween\\nvariables,\\nmake\\npredictions,\\nand\\ndevelop\\ncausal\\nmodels.\\nIt\\nis\\nused\\nin\\na\\nwide\\nvariety\\nof\\nfields\\nto\\nmake\\nbetter\\ndecisions\\nand\\nimprove\\noutcomes.', metadata={'source': '/content/Report - Importance and the use of correlation in Statistics.pdf', 'page': 2})]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-cR2wtvFcvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}